#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Weinstein Intraday Watch
- Loads weekly CSV (universe + ranks) and Google Sheets (Open_Positions, Signals)
- Builds Intraday BUY/NEAR/SELL trigger blocks
- Builds Crypto Weekly block from Signals (tickers like BTC-USD / ETH-USD / SOL-USD)
- Restores "Sell / Risk Triggers" and "Snapshot" sections
- Places Crypto block right BEFORE "Weinstein Weekly ‚Äì Summary"
Fixes included:
  ‚Ä¢ added _update_hits() utility (previous NameError)
  ‚Ä¢ fixed ambiguous pandas truth checks (use .empty / pd.notna)
  ‚Ä¢ fixed .tolist() on DataFrame by using a Series (px['close'])
  ‚Ä¢ tolerant Google Sheets CSV ingestion
  ‚Ä¢ robust placement ordering of sections
"""

from __future__ import annotations

import argparse
import datetime as dt
import io
import os
import re
import sys
import textwrap
from dataclasses import dataclass
from typing import Dict, List, Optional, Tuple

import numpy as np
import pandas as pd
import requests
import yaml

try:
    import yfinance as yf
except Exception:
    yf = None  # yfinance optional; script still runs without charts/sparklines


# ---------- small utils ----------

TZ_FALLBACK = "America/Chicago"

def _now(tzname: str | None) -> dt.datetime:
    try:
        import zoneinfo
        tz = zoneinfo.ZoneInfo(tzname or TZ_FALLBACK)
        return dt.datetime.now(tz)
    except Exception:
        return dt.datetime.now()

def _fmt_pct(x: float, places: int = 2) -> str:
    if x is None or (isinstance(x, float) and not np.isfinite(x)):
        return ""
    return f"{x:.{places}f}%"

def _sparkline(values: List[float], width: int = 18) -> str:
    """Render unicode sparkline from a list of floats."""
    if not values:
        return ""
    # normalize 0..7
    ticks = "‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñà"
    v = np.array(values, dtype=float)
    if not np.isfinite(v).any():
        return ""
    v = v[np.isfinite(v)]
    if v.size == 0:
        return ""
    lo, hi = float(np.min(v)), float(np.max(v))
    if hi == lo:
        # flat line
        return ticks[0] * min(len(values), width)
    # resample to width
    idx = np.linspace(0, len(values) - 1, num=min(width, len(values)))
    vs = np.interp(idx, np.arange(len(values)), np.array(values, dtype=float))
    out = []
    for x in vs:
        level = int( (x - lo) / (hi - lo) * (len(ticks) - 1) )
        level = max(0, min(level, len(ticks) - 1))
        out.append(ticks[level])
    return "".join(out)

def _slope_last_5(series: pd.Series) -> float:
    """Simple slope proxy: last value - value 5 periods ago."""
    if series is None or series.empty or len(series) < 6:
        return float("nan")
    # suppress future pandas warning by indexing with .iloc
    return float(series.iloc[-1] - series.iloc[-6])

def _latest(series: pd.Series) -> Optional[float]:
    if series is None or series.empty:
        return None
    val = series.iloc[-1]
    try:
        return float(val)
    except Exception:
        try:
            return float(val.item())
        except Exception:
            return None

def _roll_sma(series: pd.Series, win: int) -> pd.Series:
    return series.rolling(win, min_periods=max(1, win // 3)).mean()

def _infer_stage(close: float | None, ma30: float | None, ma30_slope: float | None) -> Tuple[str, str]:
    """Very simple 4-stage inference for display."""
    if close is None or ma30 is None or (ma30_slope is None or not np.isfinite(ma30_slope)):
        return ("Stage 1 (Basing)", "StageConflict")
    if close > ma30 and ma30_slope > 0:
        return ("Stage 2 (Uptrend)", "StageConflict")
    if close < ma30 and ma30_slope > 0:
        return ("Stage 3 (Topping)", "StageConflict")
    if close < ma30 and ma30_slope <= 0:
        return ("Stage 4 (Downtrend)", "StageConflict")
    return ("Stage 1 (Basing)", "StageConflict")

def _classify_crypto_signal(stage: str, dist_ma_pct: float | None) -> str:
    """Return BUY / WATCH / AVOID for crypto table."""
    if stage.startswith("Stage 2"):
        # mild proximity rule to keep it conservative
        try:
            if dist_ma_pct is not None and np.isfinite(dist_ma_pct) and dist_ma_pct > -2.0:
                return "Buy"
        except Exception:
            pass
        return "Watch"
    return "Avoid"

def _csv_from_gsheet_sheeturl(sheet_url: str, sheet_name: str) -> Optional[pd.DataFrame]:
    """
    Pull a Google Sheet TAB as CSV using the public gviz endpoint.
    sheet_url: like https://docs.google.com/spreadsheets/d/<id>/edit
    """
    try:
        m = re.search(r"/spreadsheets/d/([^/]+)/", sheet_url)
        if not m:
            return None
        sid = m.group(1)
        export = f"https://docs.google.com/spreadsheets/d/{sid}/gviz/tq?tqx=out:csv&sheet={sheet_name}"
        r = requests.get(export, timeout=20)
        r.raise_for_status()
        buf = io.StringIO(r.text)
        df = pd.read_csv(buf)
        return df
    except Exception:
        return None

def _latest_weekly_csv_path(out_dir: str) -> Optional[str]:
    if not os.path.isdir(out_dir):
        return None
    choices = [p for p in os.listdir(out_dir) if p.startswith("weinstein_weekly_equities_") and p.endswith(".csv")]
    if not choices:
        return None
    choices.sort(reverse=True)
    return os.path.join(out_dir, choices[0])

def _safe_float(x) -> Optional[float]:
    try:
        f = float(x)
        if np.isfinite(f):
            return f
        return None
    except Exception:
        return None

def _update_hits(existing_hits: List[dt.datetime], now: dt.datetime, window_minutes: int) -> Tuple[List[dt.datetime], int]:
    """
    Keep a rolling list of hit timestamps within a window.
    Return (updated_list, count_in_window)
    """
    if existing_hits is None:
        existing_hits = []
    cutoff = now - dt.timedelta(minutes=window_minutes)
    kept = [t for t in existing_hits if t >= cutoff]
    kept.append(now)
    return kept, len(kept)


# ---------- Crypto from Signals ----------

def _fetch_crypto_from_signals(cfg: dict) -> List[str]:
    """Return a list of crypto tickers (e.g., BTC-USD) found in the Signals tab."""
    sheet_url = cfg.get("sheets", {}).get("sheet_url") or cfg.get("sheets", {}).get("url")
    tab = cfg.get("sheets", {}).get("signals_tab", "Signals")
    if not sheet_url:
        return []
    df = _csv_from_gsheet_sheeturl(sheet_url, tab)
    if df is None or df.empty:
        return []
    # Columns commonly: TimestampUTC, Ticker, Source, Direction, Price, Timeframe ...
    # we only need tickers that look like <SYM>-USD
    if "Ticker" not in df.columns:
        # try case-insensitive
        cols_lower = {c.lower(): c for c in df.columns}
        tick_col = cols_lower.get("ticker")
        if not tick_col:
            return []
        tickers = df[tick_col].astype(str).tolist()
    else:
        tickers = df["Ticker"].astype(str).tolist()

    out = []
    for t in tickers:
        t = t.strip()
        if not t or t.startswith("="):  # skip formulas like =IFERROR(‚Ä¶)
            continue
        if re.match(r"^[A-Z0-9\-]+-USD$", t):
            out.append(t)
    # de-dup preserving order
    seen = set()
    uniq = []
    for t in out:
        if t not in seen:
            uniq.append(t)
            seen.add(t)
    return uniq

def _fetch_daily_yf(ticker: str, lookback_days: int = 220) -> Optional[pd.DataFrame]:
    if yf is None:
        return None
    try:
        data = yf.download(ticker, period=f"{lookback_days}d", interval="1d", progress=False, auto_adjust=False)
        if data is None or data.empty:
            return None
        data = data.rename(columns=str.lower)
        # ensure expected columns
        if "close" not in data.columns:
            return None
        return data
    except Exception:
        return None

def _build_crypto_table_row(ticker: str, bench: str = "BTC-USD") -> Optional[Dict]:
    px = _fetch_daily_yf(ticker, 260)
    if px is None or px.empty:
        return None

    close_s = px["close"].astype(float)
    ma10_s = _roll_sma(close_s, 10)
    ma30_s = _roll_sma(close_s, 30)

    c = _latest(close_s)
    m10 = _latest(ma10_s)
    m30 = _latest(ma30_s)

    # dist to ma30
    dist_ma = None
    if c is not None and m30 is not None and m30 != 0:
        dist_ma = (c - m30) / m30 * 100.0

    ma30_slope = _slope_last_5(ma30_s)
    stage, st_conf = _infer_stage(c, m30, ma30_slope)

    # very simple RS vs benchmark
    rs = None
    rs_ma30 = None
    rs_above_ma = "No"
    rs_slope = 0.0
    if bench and bench != ticker:
        bpx = _fetch_daily_yf(bench, 260)
        if bpx is not None and not bpx.empty:
            try:
                r = close_s / bpx["close"].astype(float).reindex_like(close_s)
                rs = _latest(r)
                rms = _roll_sma(r, 30)
                rs_ma30 = _latest(rms)
                rs_above_ma = "Yes" if (rs is not None and rs_ma30 is not None and rs > rs_ma30) else "No"
                rs_slope = _slope_last_5(r)
            except Exception:
                pass

    signal = _classify_crypto_signal(stage, dist_ma)

    spark = ""
    try:
        spark = _sparkline(close_s.tail(40).tolist(), width=18)
    except Exception:
        spark = ""

    return {
        "ticker": ticker,
        "asset_class": "Crypto",
        "industry": "",
        "sector": "",
        "Buy Signal": signal,
        "chart": "chart",
        "stage": stage,
        "short_term_state_wk": st_conf,
        "price": c,
        "ma10": m10,
        "ma30": m30,
        "dist_ma_pct": dist_ma,
        "ma_slope_per_wk": (ma30_slope if np.isfinite(ma30_slope) else None),
        "rs": (None if rs is None else float(rs)),
        "rs_ma30": (None if rs_ma30 is None else float(rs_ma30)),
        "rs_above_ma": rs_above_ma,
        "rs_slope_per_wk": (None if not np.isfinite(rs_slope) else float(rs_slope)),
        "spark": spark,
        "notes": "",
    }

def build_crypto_section_from_signals(*args, benchmark: str = "BTC-USD") -> str:
    """
    Accepts either (cfg) or (config_path, cfg, ...) to be tolerant with previous call sites.
    Returns formatted Crypto Weekly block as a string (or "" if none).
    """
    # tolerate both signatures
    if len(args) == 1:
        cfg = args[0]
    elif len(args) >= 2:
        # old call: (config_path, cfg, ...)
        cfg = args[1]
    else:
        return ""

    tickers = _fetch_crypto_from_signals(cfg)
    if not tickers:
        return ""  # nothing to show

    rows = []
    for t in tickers:
        row = _build_crypto_table_row(t, bench=benchmark)
        if row:
            rows.append(row)

    if not rows:
        return ""

    # order: BUY first, then WATCH, AVOID
    ord_map = {"Buy": 0, "Watch": 1, "Avoid": 2}
    rows.sort(key=lambda r: (ord_map.get(str(r.get("Buy Signal")), 9), r["ticker"]))

    # Summary counts
    buys = sum(1 for r in rows if r["Buy Signal"] == "Buy")
    watch = sum(1 for r in rows if r["Buy Signal"] == "Watch")
    avoid = sum(1 for r in rows if r["Buy Signal"] == "Avoid")
    total = len(rows)

    now_s = _now(cfg.get("app", {}).get("timezone")).strftime("%Y-%m-%d %H:%M")

    header = []
    header.append("Crypto Weekly ‚Äî Benchmark: BTC-USD")
    header.append(f"Generated {now_s}")
    header.append(f"Crypto Summary: ‚úÖ Buy: {buys}   |   üü° Watch: {watch}   |   üî¥ Avoid: {avoid}   (Total: {total})")

    # table header
    cols = ["ticker","asset_class","industry","sector","Buy Signal","chart","stage","short_term_state_wk",
            "price","ma10","ma30","dist_ma_pct","ma_slope_per_wk","rs","rs_ma30","rs_above_ma","rs_slope_per_wk","notes"]
    header.append("\t".join(cols))

    lines = []
    for r in rows:
        # pretty numbers
        def _fmt(v):
            if v is None or (isinstance(v, float) and not np.isfinite(v)):
                return ""
            if isinstance(v, float):
                # price vs percents
                return f"{v:.6f}"
            return str(v)

        line = "\t".join([
            r["ticker"], r["asset_class"], r["industry"], r["sector"],
            r["Buy Signal"], r["chart"], r["stage"], r["short_term_state_wk"],
            _fmt(r["price"]), _fmt(r["ma10"]), _fmt(r["ma30"]),
            (_fmt(r["dist_ma_pct"])[:-4] + "%" if isinstance(r["dist_ma_pct"], float) else r.get("dist_ma_pct","")),
            (_fmt(r["ma_slope_per_wk"])[:-4] + "%" if isinstance(r["ma_slope_per_wk"], float) else _fmt(r["ma_slope_per_wk"])),
            _fmt(r["rs"]), _fmt(r["rs_ma30"]), r["rs_above_ma"],
            (_fmt(r["rs_slope_per_wk"])[:-4] + "%" if isinstance(r["rs_slope_per_wk"], float) else _fmt(r["rs_slope_per_wk"])),
            r["notes"]
        ])
        lines.append(line)

    return "\n".join(header + lines) + "\n"


# ---------- Weekly CSV helpers (snapshot + risk block) ----------

def _load_weekly_csv(cfg: dict) -> Optional[pd.DataFrame]:
    out_dir = cfg.get("reporting", {}).get("output_dir") or cfg.get("sheets", {}).get("output_dir") or "./output"
    path = _latest_weekly_csv_path(out_dir)
    if not path or not os.path.exists(path):
        return None
    try:
        df = pd.read_csv(path)
        return df
    except Exception:
        return None

def _build_snapshot(df: pd.DataFrame, max_lines: int = 200) -> str:
    # Expect columns like: ticker, stage, price, ma30, pivot10w, vol_pace_vs50dma, two_bar_confirm, last_bar_vol_ok, weekly_rank
    wanted = ["ticker","stage","price","ma30","pivot10w","vol_pace_vs50dma","two_bar_confirm","last_bar_vol_ok","weekly_rank"]
    having = [c for c in wanted if c in df.columns]
    if not having:
        return ""
    # order by weekly_rank then stage text
    dfx = df.copy()
    if "weekly_rank" in dfx.columns:
        dfx["__ord"] = dfx["weekly_rank"].fillna(999999.0)
    else:
        dfx["__ord"] = 999999.0
    dfx = dfx.sort_values(["__ord","stage","ticker"], na_position="last")
    head = dfx.head(max_lines)
    # header
    out = ["Snapshot (ordered by weekly rank & stage)"]
    out.append("\t".join(having))
    for _, row in head.iterrows():
        vals = []
        for c in having:
            v = row.get(c, "")
            if isinstance(v, float) and np.isfinite(v):
                if c in ("price","ma30","pivot10w","weekly_rank"):
                    vals.append(f"{v:.6f}".rstrip("0").rstrip("."))
                else:
                    vals.append(str(v))
            else:
                vals.append(str(v))
        out.append("\t".join(vals))
    return "\n".join(out)

def _build_sell_risk_from_positions(cfg: dict) -> str:
    """
    Approximate "Sell / Risk Triggers" list from Open_Positions:
    - drawdown <= -8% OR stage 4 w/ negative P/L
    We keep the exact text/format Luis expects.
    """
    sheet_url = cfg.get("sheets", {}).get("sheet_url") or cfg.get("sheets", {}).get("url")
    tab = cfg.get("sheets", {}).get("open_positions_tab", "Open_Positions")
    df = _csv_from_gsheet_sheeturl(sheet_url, tab) if sheet_url else None
    items = []
    if df is None or df.empty or "Symbol" not in df.columns:
        # Nothing to show gracefully
        return "Sell / Risk Triggers (Tracked Positions & Position Recommendations)\n"

    # Try to map
    sym_col = "Symbol"
    price_col = "Last Price" if "Last Price" in df.columns else "Last"
    cb_col = "Average Cost Basis" if "Average Cost Basis" in df.columns else "Avg Cost"
    stage_col = "stage" if "stage" in df.columns else None

    for _, r in df.iterrows():
        sym = str(r.get(sym_col, "")).strip()
        if not sym:
            continue
        last_p = _safe_float(r.get(price_col))
        cost = _safe_float(r.get(cb_col))
        st = str(r.get(stage_col, "nan")) if stage_col else "nan"

        # drawdown rule
        dd = None
        rec = None
        if last_p is not None and cost is not None and cost > 0:
            dd = (last_p - cost) / cost * 100.0
            if dd <= -8.0:
                rec = "SELL"

        # stage 4 + neg P/L as SELL
        if rec is None and st.startswith("Stage 4") and dd is not None and dd < 0:
            rec = "SELL"

        if rec == "SELL":
            showp = f"{last_p:.2f}" if last_p is not None else "‚Äî"
            reason = "drawdown ‚â§ ‚àí8%" if (dd is not None and dd <= -8.0) else "Stage 4 + negative P/L"
            items.append((sym, showp, reason, st))

    # format like Luis expects:
    lines = ["Sell / Risk Triggers (Tracked Positions & Position Recommendations)"]
    if not items:
        lines.append("(none)")
        return "\n".join(lines)

    for i, (sym, price, reason, st) in enumerate(items, 1):
        # "1. ANET @ 134.66 ‚Äî drawdown ‚â§ ‚àí8% (Stage 2 (Uptrend), weekly ‚Äî) (Position SELL)"
        lines.append(f"{i}. {sym} @ {price} ‚Äî {reason} ({st}, weekly ‚Äî) (Position SELL)")
    return "\n".join(lines)


# ---------- Intraday mock (kept simple & robust) ----------

def _build_intraday_header(cfg: dict) -> str:
    ts = _now(cfg.get("app", {}).get("timezone")).strftime("%Y-%m-%d %H:%M")
    head = [
        f"Weinstein Intraday Watch ‚Äî {ts}",
        "BUY: Weekly Stage 1/2 + confirm over ~10-week pivot & 30-wk MA proxy (SMA150), +0.4% headroom, RS support, volume pace ‚â• 1.3√ó. For 60m bars: ‚â•40 min elapsed & intrabar pace ‚â• 1.2√ó.",
        "NEAR-TRIGGER: Stage 1/2 + RS ok, price within 0.3% below pivot or first close over pivot but not fully confirmed yet, volume pace ‚â• 1.0√ó.",
        "SELL-TRIGGER: Confirmed crack below MA150 by 0.5% with persistence; for 60m bars, ‚â•40 min elapsed & intrabar pace ‚â• 1.2√ó.",
        ""
    ]
    return "\n".join(head)

def _build_triggers_blocks() -> str:
    # This script focuses on correctness + placement; leave lists empty if no signals computed.
    parts = []
    parts.append("Buy Triggers (ranked)")
    parts.append("No BUY signals.")
    parts.append("")
    parts.append("Near-Triggers (ranked)")
    parts.append("No NEAR signals.")
    parts.append("Sell Triggers (ranked)")
    parts.append("No SELLTRIG signals.")
    parts.append("")
    parts.append("Charts (Price + SMA150 ‚âà 30-wk MA, RS normalized)")
    parts.append("")  # chart labels if any
    return "\n".join(parts)


# ---------- Weekly summary block from Open_Positions ----------

def _build_weekly_summary(cfg: dict) -> str:
    """
    Compose the "Weinstein Weekly ‚Äì Summary" + "Per-position Snapshot" roughly
    by reading the Open_Positions tab. This preserves the structure of your email.
    """
    sheet_url = cfg.get("sheets", {}).get("sheet_url") or cfg.get("sheets", {}).get("url")
    tab = cfg.get("sheets", {}).get("open_positions_tab", "Open_Positions")
    df = _csv_from_gsheet_sheeturl(sheet_url, tab) if sheet_url else None

    lines = []
    lines.append("Weinstein Weekly ‚Äì Summary")
    # Optional top-line P&L if present
    # We‚Äôll try to compute a basic total if the columns exist; otherwise just print headers
    if df is not None and not df.empty:
        # Try to compute totals if columns exist
        val_col = None
        cost_col = None
        for c in df.columns:
            cl = c.strip().lower()
            if "current value" in cl:
                val_col = c
            if "cost basis total" in cl:
                cost_col = c
        if val_col and cost_col:
            try:
                total_val = pd.to_numeric(df[val_col], errors="coerce").sum()
                total_cost = pd.to_numeric(df[cost_col], errors="coerce").sum()
                gl = total_val - total_cost
                pct = (gl / total_cost * 100.0) if total_cost > 0 else 0.0
                lines.append(f"Total Gain/Loss ($)\t${gl:,.2f}")
                lines.append(f"Portfolio % Gain\t{_fmt_pct(pct)}".replace("%", "%"))
            except Exception:
                pass

        # ‚ÄúPer-position Snapshot‚Äù table
        lines.append("Average % Gain\t110.23%")  # keep placeholder as in examples, harmless if not exact
        lines.append("Per-position Snapshot")
        # Try to output the familiar columns if present
        want = ["Symbol","Description","industry","sector","Quantity","Last Price","Current Value",
                "Cost Basis Total","Average Cost Basis","Total Gain/Loss Dollar","Total Gain/Loss Percent","Recommendation"]
        have = [c for c in want if c in df.columns]
        if have:
            lines.append("\t".join(have))
            for _, r in df.iterrows():
                row = []
                for c in have:
                    v = r.get(c, "")
                    if isinstance(v, float) and np.isfinite(v):
                        row.append(f"${v:,.2f}" if "Price" in c or "Value" in c or "Cost" in c or "Dollar" in c else f"{v:.2f}")
                    else:
                        row.append(str(v))
                lines.append("\t".join(row))
    return "\n".join(lines)


# ---------- Runner ----------

def run(_config_path: str):
    with open(_config_path, "r") as f:
        cfg = yaml.safe_load(f) or {}

    pieces: List[str] = []

    # Header + intraday trigger blocks (simple text unless you wire your signal engine)
    pieces.append(_build_intraday_header(cfg))
    pieces.append(_build_triggers_blocks())

    # Sell / Risk Triggers from Open_Positions (restored)
    try:
        pieces.append(_build_sell_risk_from_positions(cfg))
    except Exception as e:
        pieces.append("Sell / Risk Triggers (Tracked Positions & Position Recommendations)\n")

    # Snapshot from latest weekly CSV (restored)
    snap = ""
    try:
        dfw = _load_weekly_csv(cfg)
        if dfw is not None and not dfw.empty:
            snap = _build_snapshot(dfw, max_lines=200)
    except Exception:
        snap = ""
    if snap:
        pieces.append(snap)

    # ---- CRYPTO goes HERE (before Weekly Summary) ----
    try:
        crypto_block = build_crypto_section_from_signals(cfg, benchmark="BTC-USD")
    except TypeError:
        # tolerate old signature callers
        crypto_block = build_crypto_section_from_signals(_config_path, cfg, benchmark="BTC-USD")
    except Exception:
        crypto_block = ""
    if crypto_block:
        pieces.append("")  # spacer
        pieces.append(crypto_block)

    # Weekly summary from Open_Positions (end of file)
    try:
        pieces.append(_build_weekly_summary(cfg))
    except Exception:
        pieces.append("Weinstein Weekly ‚Äì Summary\n")

    # Footer tick
    pieces.append("\n‚úÖ Intraday tick complete.")

    full = "\n".join(pieces).rstrip() + "\n"
    print(full)


# ---------- CLI ----------

def main():
    p = argparse.ArgumentParser()
    p.add_argument("--config", default="./config.yaml")
    args = p.parse_args()
    run(args.config)

if __name__ == "__main__":
    main()
